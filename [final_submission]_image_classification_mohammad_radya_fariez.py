# -*- coding: utf-8 -*-
"""[Final Submission] Image Classification - Mohammad Radya Fariez.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wm20Pr5N88gMp9Q8F1_WGwC-_-j9Af-G
"""

# Mohammad Radya Fariez
# email : radya.fariez@gmail.com
# Kota Tangerang Selatan, Banten

# Commented out IPython magic to ensure Python compatibility.
# import lib
import numpy as np
import pandas as pd
import tensorflow as tf
import zipfile, os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# %matplotlib inline

# load dataset
#from google.colab import files
#uploaded = files.upload()
!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

#ekstrak file zip
#local_zip = io.BytesIO(downloaded.encode('rockpaperscissors.zip.1'))
#zip_ref = zipfile.ZipFile(local_zip, "r")
#zip_ref.extractall('/content/')
#zip_ref.close()
!unzip 'rockpaperscissors.zip.4'

# Mendeklarasikan folder untuk gambar batu gunting kertas
folder_batu = os.path.join('/content/rockpaperscissors/rock')
folder_gunting = os.path.join('/content/rockpaperscissors/scissors')
folder_kertas = os.path.join('/content/rockpaperscissors/paper')

# Total jumlah gambar per item
print('Jumlah batu -', len(os.listdir(folder_batu)))
print('Jumlah gunting -', len(os.listdir(folder_gunting)))
print('Jumlah kertas -', len(os.listdir(folder_kertas)))

# Cetak gambar per item
file_batu = os.listdir(folder_batu)
print("Batu -",file_batu[:5])

file_gunting = os.listdir(folder_gunting)
print("Gunting -",file_gunting[:5])

file_kertas = os.listdir(folder_kertas)
print("Kertas -",file_kertas[:5])

# Tampil gambar
pic_index = 0
nrows = 3
ncols = 4

fig = plt.gcf()
fig.set_size_inches(nrows * 3, ncols * 4)
pic_index += 4

fig_batu = [os.path.join(folder_batu, fname)
            for fname in file_batu[pic_index-4:pic_index]]
fig_gunting = [os.path.join(folder_gunting, fname)
            for fname in file_gunting[pic_index-4:pic_index]]
fig_kertas = [os.path.join(folder_kertas, fname)
            for fname in file_kertas[pic_index-4:pic_index]]

for i, img_path in enumerate(fig_batu + fig_gunting + fig_kertas):
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off')
  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

# Import module
import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

Base_Directory = '/content/rockpaperscissors/rps-cv-images/'

#Augmentation Data & Train Test Split
training_data = ImageDataGenerator(
      rescale = 1./255,
      rotation_range = 35,
      width_shift_range = 0.2,
      height_shift_range = 0.2,
      shear_range = 0.2,
      zoom_range = 0.2,
      horizontal_flip = True,
      fill_mode = 'nearest',
      validation_split = 0.4
    )

test_data = ImageDataGenerator(
                rescale = 1./255
)

train_generator = training_data.flow_from_directory(
        Base_Directory,
        target_size = (150,150),  #pixel size
        class_mode = 'categorical',  #multiclass
    shuffle = True,
    subset = 'training'
)

validation_generator = training_data.flow_from_directory(
        Base_Directory,
        target_size = (150,150), 
        class_mode = 'categorical',  
    shuffle = True,
    subset = 'validation'
)

#Pembentukan model sequential
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150,150,3)),  #layer konvolusi ke-1
    tf.keras.layers.MaxPooling2D(2, 2),  

    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'), #layer konvolusi ke-2
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'), #layer konvolusi ke-3
    tf.keras.layers.MaxPooling2D(2, 2),   

    tf.keras.layers.Flatten(),  #layer input untuk deep learning NN
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(128, activation = 'relu'),  #hidden layer ke-1
    tf.keras.layers.Dense(512, activation = 'relu'),  #hidden layer ke-2
    tf.keras.layers.Dense(3, activation = 'softmax')  #layer output
])

model.summary()

#compile model
model.compile(loss = 'binary_crossentropy',
              optimizer = tf.optimizers.Adam(),
              metrics = ['accuracy'])

#train model NN
history = model.fit(
      train_generator,
      steps_per_epoch = 20,  #jumlah batch yang akan dieksekusi
      epochs = 25, 
      validation_data = validation_generator, #untuk tampilan akurasi
      validation_steps = 5,  # jumlah batch yang akan dieksekusi pada setiap epoch
      verbose = 2)

#Uji Coba Model
from google.colab import files
uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size = (150, 150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis = 0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size = 10)
  print(fn)

  if classes[0][0] == 1:
    print('Classified as Paper')
  elif classes[0][1] == 1:
    print('Classified as Rock')
  elif classes[0][2] == 1:
    print('Classified as Scissors')
  else:
    print('Unknown')

#plotting nilai akurasi dan validasi
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.title('Training vs Validation Accuracy')
plt.plot(epochs, acc, 'r', label = 'Training Accuracy')
plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')
plt.legend(loc = 0)
plt.figure()
plt.show()